{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf83ddd6-60ce-4041-a86a-c59e4b1cbef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Cell 1: Setup and Imports\n",
    "--------------------------\n",
    "This cell performs the following:\n",
    " - Sets the GPU configuration via environment variables.\n",
    " - Imports common libraries (numpy, pandas, torch, etc.).\n",
    " - Configures warnings, CUDA, and deterministic behavior.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "gpus = [0]\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.backends import cudnn\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "\n",
    "# Import auxiliary libraries and modules\n",
    "from pandas import ExcelWriter\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from einops import rearrange, reduce, repeat\n",
    "\n",
    "# Importing custom utility functions (make sure utils.py is in your working directory)\n",
    "from utils import calMetrics, calculatePerClass, numberClassChannel, load_data_evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80eb8524-a149-4d0d-9827-43b64091ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell 2: Mamba Fallback Module\n",
    "-----------------------------\n",
    "- Tries to import the actual Mamba SSM implementation.\n",
    "- In the event that the package is missing, a dummy class is defined.\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    from mamba_ssm import Mamba\n",
    "except ImportError:\n",
    "    class Mamba(nn.Module):\n",
    "        \"\"\"\n",
    "        Dummy fallback if mamba_ssm is not installed.\n",
    "        This simply acts like a linear layer for demonstration.\n",
    "        \"\"\"\n",
    "        print(\"using DUmmy\")\n",
    "        def __init__(self, d_model, d_state=16, d_conv=4, expand=2):\n",
    "            super().__init__()\n",
    "            self.linear = nn.Linear(d_model, d_model)\n",
    "        def forward(self, x):\n",
    "            # x shape: (batch, seq_len, d_model)\n",
    "            return self.linear(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667f5b38-04e3-4db6-9175-33f5b7659938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Mamba SSM Module: Use the official implementation if available, else a dummy.\n",
    "# -----------------------------------------------------------------------------\n",
    "try:\n",
    "    from mamba_ssm import Mamba  # Assumed to implement a parameter‐efficient SSM.\n",
    "except ImportError:\n",
    "    class Mamba(nn.Module):\n",
    "        \"\"\"\n",
    "        Dummy fallback for Mamba SSM. In practice, this should be replaced\n",
    "        with the actual implementation of Mamba SSM.\n",
    "        \"\"\"\n",
    "        def __init__(self, d_model, d_state=16, d_conv=4, expand=2):\n",
    "            super().__init__()\n",
    "            self.linear = nn.Linear(d_model, d_model)\n",
    "        def forward(self, x):\n",
    "            return self.linear(x)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CNN Embedding Module (PatchEmbeddingCNN)\n",
    "# -----------------------------------------------------------------------------\n",
    "class PatchEmbeddingCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    This module extracts temporal and spatial features from EEG signals.\n",
    "    \n",
    "    It first applies a temporal convolution with a large kernel (e.g., 1000) \n",
    "    that spans nearly an entire epoch. Then a depthwise spatial convolution \n",
    "    (with kernel=(number_channel,1)) aggregates channel information. An \n",
    "    average-pooling along the time axis downsamples the sequence. A further \n",
    "    spatial convolution (kernel=(1, additional_kernel)) refines the representation.\n",
    "    \n",
    "    Finally, a 1×1 projection maps the features to the desired embedding size,\n",
    "    and a rearrangement produces a sequence of patch embeddings.\n",
    "    \n",
    "    Input shape: [batch, 1, number_channel, time]\n",
    "    Output shape: [batch, seq_len, emb_size]\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 f1=16, \n",
    "                 kernel_size=1000, \n",
    "                 pooling_size1=8, \n",
    "                 pooling_size2=8, \n",
    "                 dropout_rate=0.3, \n",
    "                 number_channel=22, \n",
    "                 emb_size=40,\n",
    "                 additional_kernel=16):\n",
    "        super().__init__()\n",
    "        # First, temporal convolution: captures long-range temporal dependencies.\n",
    "        # Using a large kernel_size (e.g., 1000) gives broad temporal context.\n",
    "        self.cnn_module = nn.Sequential(\n",
    "            nn.Conv2d(1, f1, kernel_size=(1, kernel_size), stride=(1,1), \n",
    "                      padding='same', bias=False),\n",
    "            nn.BatchNorm2d(f1),\n",
    "            nn.ELU(),\n",
    "            # Depthwise spatial convolution: aggregates information across channels.\n",
    "            nn.Conv2d(f1, f1 * 2, kernel_size=(number_channel, 1), stride=(1,1), \n",
    "                      groups=f1, padding='valid', bias=False),\n",
    "            nn.BatchNorm2d(f1 * 2),\n",
    "            nn.ELU(),\n",
    "            # First average pooling along time.\n",
    "            nn.AvgPool2d(kernel_size=(1, pooling_size1)),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            # Additional spatial convolution to further refine features.\n",
    "            nn.Conv2d(f1 * 2, f1 * 2, kernel_size=(1, additional_kernel), stride=(1,1),\n",
    "                      padding='same', bias=False),\n",
    "            nn.BatchNorm2d(f1 * 2),\n",
    "            nn.ELU(),\n",
    "            # Second average pooling along time.\n",
    "            nn.AvgPool2d(kernel_size=(1, pooling_size2)),\n",
    "            nn.Dropout(dropout_rate),\n",
    "        )\n",
    "        # The current number of channels output by cnn_module is (f1 * 2).\n",
    "        # We then project this via a 1x1 convolution to the desired emb_size.\n",
    "        self.proj_layer = nn.Conv2d(f1 * 2, emb_size, kernel_size=1, bias=False)\n",
    "        # Rearrangement from [batch, emb_size, 1, t] to [batch, t, emb_size]\n",
    "        self.projection = Rearrange('b c 1 t -> b t c')\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x shape: [batch, 1, number_channel, time]\n",
    "        x = self.cnn_module(x)\n",
    "        x = self.proj_layer(x)\n",
    "        x = self.projection(x)\n",
    "        return x\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Classification Head\n",
    "# -----------------------------------------------------------------------------\n",
    "class ClassificationHead(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple classification head that applies dropout and a final linear mapping.\n",
    "    \n",
    "    Input: a flattened feature vector.\n",
    "    \"\"\"\n",
    "    def __init__(self, flatten_number, n_classes):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(flatten_number, n_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Positional Encoding\n",
    "# -----------------------------------------------------------------------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Adds trainable positional encodings to the input sequence.\n",
    "    \n",
    "    Input: [batch, seq_len, emb_size]\n",
    "    Output: [batch, seq_len, emb_size]\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding, max_len=150, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Trainable positional encodings.\n",
    "        self.encoding = nn.Parameter(torch.randn(1, max_len, embedding))\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        seq_len = x.shape[1]\n",
    "        if seq_len > self.encoding.shape[1]:\n",
    "            raise ValueError(\"Sequence length exceeds positional encoding length\")\n",
    "        x = x + self.encoding[:, :seq_len, :].to(x.device)\n",
    "        return self.dropout(x)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Mamba Encoder Blocks\n",
    "# -----------------------------------------------------------------------------\n",
    "class MambaEncoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    An encoder block that first applies layer normalization,\n",
    "    then a Mamba SSM (for sequence modeling) with dropout (and residual connection),\n",
    "    followed by a feedforward network with GELU activation and dropout (with residual).\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, d_state=16, d_conv=4, expand=2, dropout=0.5, ff_expansion=4):\n",
    "        super().__init__()\n",
    "        self.mamba_norm = nn.LayerNorm(d_model)\n",
    "        self.mamba = Mamba(d_model=d_model, d_state=d_state, d_conv=d_conv, expand=expand)\n",
    "        self.mamba_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.ffn_norm = nn.LayerNorm(d_model)\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_expansion * d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(ff_expansion * d_model, d_model)\n",
    "        )\n",
    "        self.ffn_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # First residual branch.\n",
    "        y = self.mamba_norm(x)\n",
    "        y = self.mamba(y)\n",
    "        y = self.mamba_dropout(y)\n",
    "        x = x + y\n",
    "        # Second residual branch.\n",
    "        z = self.ffn_norm(x)\n",
    "        z = self.feedforward(z)\n",
    "        z = self.ffn_dropout(z)\n",
    "        x = x + z\n",
    "        return x\n",
    "\n",
    "class MambaEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Stacks multiple MambaEncoderBlocks to build the deep encoder.\n",
    "    \"\"\"\n",
    "    def __init__(self, depth=6, d_model=40, d_state=16, d_conv=4, expand=2, dropout=0.5, ff_expansion=4):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            MambaEncoderBlock(d_model, d_state, d_conv, expand, dropout, ff_expansion)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# EEGMamba: The Full Model Assembly\n",
    "# -----------------------------------------------------------------------------\n",
    "class EEGMamba(nn.Module):\n",
    "    \"\"\"\n",
    "    A complete EEG-based motor imagery classifier that uses the CNN-based\n",
    "    patch embedding (with full temporal and spatial processing), positional\n",
    "    encoding, and stacked Mamba SSM encoder blocks in place of a Transformer.\n",
    "    \n",
    "    It flattens the final features and applies a classification head.\n",
    "    \n",
    "    For BCI Competition IV–2a, expected input shape is [batch, 1, 22, 1000].\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 emb_size=40,\n",
    "                 depth=6,\n",
    "                 n_classes=None,   # Must be provided from dataset (e.g., 4 for IV-2a)\n",
    "                 eeg1_f1=16,\n",
    "                 eeg1_kernel_size=1000,\n",
    "                 eeg1_pooling_size1=8,\n",
    "                 eeg1_pooling_size2=8,\n",
    "                 eeg1_dropout_rate=0.3,\n",
    "                 eeg1_number_channel=22,\n",
    "                 d_state=16,\n",
    "                 d_conv=4,\n",
    "                 expand=2,\n",
    "                 ff_expansion=4,\n",
    "                 dropout_mamba=0.5,\n",
    "                 max_pos_len=150):\n",
    "        super().__init__()\n",
    "        if n_classes is None:\n",
    "            raise ValueError(\"n_classes must be provided\")\n",
    "        self.n_classes = n_classes\n",
    "        self.emb_size = emb_size\n",
    "        \n",
    "        # CNN embedding: produces a sequence of patch embeddings.\n",
    "        self.cnn = PatchEmbeddingCNN(\n",
    "            f1=eeg1_f1,\n",
    "            kernel_size=eeg1_kernel_size,\n",
    "            pooling_size1=eeg1_pooling_size1,\n",
    "            pooling_size2=eeg1_pooling_size2,\n",
    "            dropout_rate=eeg1_dropout_rate,\n",
    "            number_channel=eeg1_number_channel,\n",
    "            emb_size=emb_size\n",
    "        )\n",
    "        # Positional encoding: adds trainable positional information.\n",
    "        self.position = PositionalEncoding(embedding=emb_size, max_len=max_pos_len, dropout=0.1)\n",
    "        # Mamba encoder blocks for sequence modeling.\n",
    "        self.mamba_encoder = MambaEncoder(\n",
    "            depth=depth,\n",
    "            d_model=emb_size,\n",
    "            d_state=d_state,\n",
    "            d_conv=d_conv,\n",
    "            expand=expand,\n",
    "            dropout=dropout_mamba,\n",
    "            ff_expansion=ff_expansion\n",
    "        )\n",
    "        \n",
    "        # Compute the output sequence length from CNN by forwarding a dummy input.\n",
    "        dummy_input = torch.randn(1, 1, eeg1_number_channel, 1000)\n",
    "        with torch.no_grad():\n",
    "            dummy_out = self.cnn(dummy_input)  # shape: [1, seq_len, emb_size]\n",
    "        seq_len = dummy_out.shape[1]\n",
    "        flatten_size = seq_len * emb_size\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.classification = ClassificationHead(flatten_size, self.n_classes)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x: [batch, 1, number_channel, time]\n",
    "        cnn_out = self.cnn(x)  # -> [batch, seq_len, emb_size]\n",
    "        # Scale features\n",
    "        cnn_scaled = cnn_out * math.sqrt(self.emb_size)\n",
    "        # Add positional encoding\n",
    "        pos_encoded = self.position(cnn_scaled)\n",
    "        # Process with Mamba encoder blocks\n",
    "        features = self.mamba_encoder(pos_encoded)\n",
    "        # Flatten and classify\n",
    "        flat = self.flatten(features)\n",
    "        out = self.classification(flat)\n",
    "        return features, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a1f404d-6eab-4743-a520-e5a8489013dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell 7: Experiment Class (ExP)\n",
    "------------------------------\n",
    "- Encapsulates the complete training, validation, and testing pipeline.\n",
    "- Contains methods:\n",
    "  - `interaug`: Performs data augmentation by segmenting the input data.\n",
    "  - `get_source_data`: Loads and standardizes the data.\n",
    "  - `train`: Contains the training loop, validation step, and final testing.\n",
    "- Saves the best model and writes training/logging results to Excel files.\n",
    "\"\"\"\n",
    "\n",
    "class ExP():\n",
    "    def __init__(self, nsub, data_dir, result_name, \n",
    "                 epochs=2000, \n",
    "                 number_aug=2,\n",
    "                 number_seg=8, \n",
    "                 gpus=[0], \n",
    "                 evaluate_mode='subject-dependent',\n",
    "                 heads=4, \n",
    "                 emb_size=40,\n",
    "                 depth=6, \n",
    "                 dataset_type='A',\n",
    "                 eeg1_f1=20,\n",
    "                 eeg1_kernel_size=64,\n",
    "                 eeg1_D=2,\n",
    "                 eeg1_pooling_size1=8,\n",
    "                 eeg1_pooling_size2=8,\n",
    "                 eeg1_dropout_rate=0.3,\n",
    "                 validate_ratio=0.2,\n",
    "                 learning_rate=0.001,\n",
    "                 batch_size=72):\n",
    "        \n",
    "        super(ExP, self).__init__()\n",
    "        self.dataset_type = dataset_type\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = learning_rate\n",
    "        self.n_epochs = epochs\n",
    "        self.nSub = nsub\n",
    "        self.number_augmentation = number_aug\n",
    "        self.number_seg = number_seg\n",
    "        self.root = data_dir\n",
    "        self.heads = heads\n",
    "        self.emb_size = emb_size\n",
    "        self.depth = depth\n",
    "        self.result_name = result_name\n",
    "        self.evaluate_mode = evaluate_mode\n",
    "        self.validate_ratio = validate_ratio\n",
    "\n",
    "        self.Tensor = torch.cuda.FloatTensor\n",
    "        self.LongTensor = torch.cuda.LongTensor\n",
    "        self.criterion_cls = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "        # Get number of classes and channels from your dataset type.\n",
    "        self.number_class, self.number_channel = numberClassChannel(self.dataset_type)\n",
    "        \n",
    "        # ----- Updated EEGMamba instantiation -----\n",
    "        # Instead of passing 'database_type' and 'flatten_eeg1', pass 'n_classes'\n",
    "        self.model = EEGMamba(\n",
    "            emb_size=self.emb_size,\n",
    "            depth=self.depth,\n",
    "            n_classes=self.number_class,  # Use the number of classes here.\n",
    "            eeg1_f1=eeg1_f1,\n",
    "            eeg1_kernel_size=eeg1_kernel_size,\n",
    "            eeg1_D=eeg1_D,\n",
    "            eeg1_pooling_size1=eeg1_pooling_size1,\n",
    "            eeg1_pooling_size2=eeg1_pooling_size2,\n",
    "            eeg1_dropout_rate=eeg1_dropout_rate,\n",
    "            eeg1_number_channel=self.number_channel\n",
    "        ).cuda()\n",
    "        self.model_filename = self.result_name + '/model_{}.pth'.format(self.nSub)\n",
    "        \n",
    "        # Continue with the rest of your initialization...\n",
    "\n",
    "\n",
    "    def interaug(self, timg, label):  \n",
    "        # Data augmentation: randomly selects segments from class-specific data.\n",
    "        aug_data = []\n",
    "        aug_label = []\n",
    "        number_records_by_augmentation = self.number_augmentation * int(self.batch_size / self.number_class)\n",
    "        number_segmentation_points = 1000 // self.number_seg\n",
    "        for clsAug in range(self.number_class):\n",
    "            cls_idx = np.where(label == clsAug + 1)\n",
    "            tmp_data = timg[cls_idx]\n",
    "            tmp_label = label[cls_idx]\n",
    "            \n",
    "            tmp_aug_data = np.zeros((number_records_by_augmentation, 1, self.number_channel, 1000))\n",
    "            for ri in range(number_records_by_augmentation):\n",
    "                for rj in range(self.number_seg):\n",
    "                    rand_idx = np.random.randint(0, tmp_data.shape[0], self.number_seg)\n",
    "                    tmp_aug_data[ri, :, :, rj * number_segmentation_points:(rj + 1) * number_segmentation_points] = \\\n",
    "                        tmp_data[rand_idx[rj], :, :, rj * number_segmentation_points:(rj + 1) * number_segmentation_points]\n",
    "            aug_data.append(tmp_aug_data)\n",
    "            aug_label.append(tmp_label[:number_records_by_augmentation])\n",
    "        aug_data = np.concatenate(aug_data)\n",
    "        aug_label = np.concatenate(aug_label)\n",
    "        aug_shuffle = np.random.permutation(len(aug_data))\n",
    "        aug_data = aug_data[aug_shuffle, :, :]\n",
    "        aug_label = aug_label[aug_shuffle]\n",
    "\n",
    "        aug_data = torch.from_numpy(aug_data).cuda().float()\n",
    "        aug_label = torch.from_numpy(aug_label-1).cuda().long()\n",
    "        return aug_data, aug_label\n",
    "\n",
    "    def get_source_data(self):\n",
    "        # Loads training and testing data\n",
    "        (self.train_data,\n",
    "         self.train_label, \n",
    "         self.test_data, \n",
    "         self.test_label) = load_data_evaluate(self.root, self.dataset_type, self.nSub, mode_evaluate=self.evaluate_mode)\n",
    "\n",
    "        self.train_data = np.expand_dims(self.train_data, axis=1)\n",
    "        self.train_label = np.transpose(self.train_label)\n",
    "        self.allData = self.train_data\n",
    "        self.allLabel = self.train_label[0]\n",
    "\n",
    "        # Shuffle training data\n",
    "        shuffle_num = np.random.permutation(len(self.allData))\n",
    "        self.allData = self.allData[shuffle_num, :, :, :]\n",
    "        self.allLabel = self.allLabel[shuffle_num]\n",
    "\n",
    "        print('-'*20, \"train size：\", self.train_data.shape, \"test size：\", self.test_data.shape)\n",
    "        self.test_data = np.expand_dims(self.test_data, axis=1)\n",
    "        self.test_label = np.transpose(self.test_label)\n",
    "        self.testData = self.test_data\n",
    "        self.testLabel = self.test_label[0]\n",
    "\n",
    "        # Standardize the data based on training set statistics\n",
    "        target_mean = np.mean(self.allData)\n",
    "        target_std = np.std(self.allData)\n",
    "        self.allData = (self.allData - target_mean) / target_std\n",
    "        self.testData = (self.testData - target_mean) / target_std\n",
    "        \n",
    "        return self.allData, self.allLabel, self.testData, self.testLabel\n",
    "\n",
    "    def train(self):\n",
    "        img, label, test_data, test_label = self.get_source_data()\n",
    "        \n",
    "        img = torch.from_numpy(img)\n",
    "        label = torch.from_numpy(label - 1)\n",
    "        dataset = torch.utils.data.TensorDataset(img, label)\n",
    "        \n",
    "        test_data = torch.from_numpy(test_data)\n",
    "        test_label = torch.from_numpy(test_label - 1)\n",
    "        test_dataset = torch.utils.data.TensorDataset(test_data, test_label)\n",
    "        self.test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        # Optimizer setup\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, betas=(self.b1, self.b2))\n",
    "        test_data = Variable(test_data.type(self.Tensor))\n",
    "        test_label = Variable(test_label.type(self.LongTensor))\n",
    "        best_epoch = 0\n",
    "        min_loss = 100\n",
    "        result_process = []\n",
    "        for e in range(self.n_epochs):\n",
    "            self.dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)\n",
    "            epoch_process = {'epoch': e}\n",
    "            self.model.train()\n",
    "            outputs_list = []\n",
    "            label_list = []\n",
    "\n",
    "            val_data_list = []\n",
    "            val_label_list = []\n",
    "\n",
    "            for i, (img_batch, label_batch) in enumerate(self.dataloader):\n",
    "                number_sample = img_batch.shape[0]\n",
    "                number_validate = int(self.validate_ratio * number_sample)\n",
    "\n",
    "                # Split batch for training and validation\n",
    "                train_data = img_batch[:-number_validate]\n",
    "                train_label = label_batch[:-number_validate]\n",
    "\n",
    "                val_data_list.append(img_batch[number_validate:])\n",
    "                val_label_list.append(label_batch[number_validate:])\n",
    "\n",
    "                img_batch = Variable(train_data.type(self.Tensor))\n",
    "                label_batch = Variable(train_label.type(self.LongTensor))\n",
    "\n",
    "                # Data augmentation step\n",
    "                aug_data, aug_label = self.interaug(self.allData, self.allLabel)\n",
    "                # Concatenate original and augmented data\n",
    "                img_batch = torch.cat((img_batch, aug_data))\n",
    "                label_batch = torch.cat((label_batch, aug_label))\n",
    "\n",
    "                features, outputs = self.model(img_batch)\n",
    "                outputs_list.append(outputs)\n",
    "                label_list.append(label_batch)\n",
    "                loss = self.criterion_cls(outputs, label_batch)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # Validation step\n",
    "            self.model.eval()\n",
    "            val_data = torch.cat(val_data_list).cuda()\n",
    "            val_label = torch.cat(val_label_list).cuda()\n",
    "            val_data = val_data.type(self.Tensor)\n",
    "            val_label = val_label.type(self.LongTensor)\n",
    "\n",
    "            val_dataset = torch.utils.data.TensorDataset(val_data, val_label)\n",
    "            val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "            outputs_list = []\n",
    "            with torch.no_grad():\n",
    "                for i, (img_v, _) in enumerate(val_dataloader):\n",
    "                    img_v = img_v.type(self.Tensor).cuda()\n",
    "                    _, Cls = self.model(img_v)\n",
    "                    outputs_list.append(Cls)\n",
    "            Cls = torch.cat(outputs_list)\n",
    "\n",
    "            val_loss = self.criterion_cls(Cls, val_label)\n",
    "            val_pred = torch.max(Cls, 1)[1]\n",
    "            val_acc = float((val_pred == val_label).cpu().numpy().sum()) / float(val_label.size(0))\n",
    "            epoch_process.update({'val_acc': val_acc, 'val_loss': val_loss.detach().cpu().numpy()})\n",
    "\n",
    "            # Compute training accuracy from the last batch\n",
    "            train_pred = torch.max(outputs, 1)[1]\n",
    "            train_acc = float((train_pred == label_batch).cpu().numpy().sum()) / float(label_batch.size(0))\n",
    "            epoch_process.update({'train_acc': train_acc, 'train_loss': loss.detach().cpu().numpy()})\n",
    "\n",
    "            # Save model if current validation loss is the minimum\n",
    "            if val_loss < min_loss:\n",
    "                min_loss = val_loss\n",
    "                best_epoch = e\n",
    "                torch.save(self.model, self.model_filename)\n",
    "                print(\"{}_{} train_acc: {:.4f} train_loss: {:.6f}\\tval_acc: {:.6f} val_loss: {:.7f}\".format(\n",
    "                    self.nSub, e, train_acc, loss.detach().cpu().numpy(), val_acc, val_loss.detach().cpu().numpy()\n",
    "                ))\n",
    "\n",
    "            result_process.append(epoch_process)\n",
    "\n",
    "        # Load the best model and evaluate on test set\n",
    "        self.model.eval()\n",
    "        from torch.serialization import safe_globals\n",
    "        with safe_globals([EEGMamba, PatchEmbeddingCNN, PositioinalEncoding, ClassificationHead, \n",
    "                            MambaEncoder, MambaEncoderBlock, nn.Sequential]):\n",
    "            self.model = torch.load(self.model_filename, weights_only=False)\n",
    "        self.model = self.model.cuda()\n",
    "\n",
    "        outputs_list = []\n",
    "        with torch.no_grad():\n",
    "            for i, (img_batch, label_batch) in enumerate(self.test_dataloader):\n",
    "                img_test = Variable(img_batch.type(self.Tensor)).cuda()\n",
    "                features, outputs = self.model(img_test)\n",
    "                outputs_list.append(outputs)\n",
    "        outputs = torch.cat(outputs_list)\n",
    "        y_pred = torch.max(outputs, 1)[1]\n",
    "\n",
    "        test_acc = float((y_pred == test_label).cpu().numpy().sum()) / float(test_label.size(0))\n",
    "        print(\"epoch: \", best_epoch, '\\tThe test accuracy is:', test_acc)\n",
    "\n",
    "        df_process = pd.DataFrame(result_process)\n",
    "        return test_acc, test_label, y_pred, df_process, best_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a57e7bbd-0e21-4fd0-a747-17a5a6f12c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell 8: Main Function\n",
    "----------------------\n",
    "- The main function handles the following:\n",
    "  - Iterating over each subject.\n",
    "  - Instantiating the ExP experiment class and training the model.\n",
    "  - Collecting results and writing them to Excel workbooks.\n",
    "- It finally returns a DataFrame summarizing the performance.\n",
    "\"\"\"\n",
    "\n",
    "def main(dirs,                \n",
    "         evaluate_mode='subject-dependent',\n",
    "         heads=8,           \n",
    "         emb_size=48,       \n",
    "         depth=3,           \n",
    "         dataset_type='A',  \n",
    "         eeg1_f1=20,\n",
    "         eeg1_kernel_size=64,\n",
    "         eeg1_D=2,\n",
    "         eeg1_pooling_size1=8,\n",
    "         eeg1_pooling_size2=8,\n",
    "         eeg1_dropout_rate=0.3,\n",
    "         flatten_eeg1=600,   \n",
    "         validate_ratio=0.2):\n",
    "    \n",
    "    if not os.path.exists(dirs):\n",
    "        os.makedirs(dirs)\n",
    "\n",
    "    result_write_metric = ExcelWriter(dirs + \"/result_metric.xlsx\")\n",
    "    process_write = ExcelWriter(dirs + \"/process_train.xlsx\")\n",
    "    pred_true_write = ExcelWriter(dirs + \"/pred_true.xlsx\")\n",
    "\n",
    "    result_metric_dict = {}\n",
    "    y_true_pred_dict = {}\n",
    "    subjects_result = []\n",
    "    best_epochs = []\n",
    "\n",
    "    for i in range(N_SUBJECT):\n",
    "        starttime = datetime.datetime.now()\n",
    "        seed_n = np.random.randint(2024)\n",
    "        print('seed is ' + str(seed_n))\n",
    "        random.seed(seed_n)\n",
    "        np.random.seed(seed_n)\n",
    "        torch.manual_seed(seed_n)\n",
    "        torch.cuda.manual_seed(seed_n)\n",
    "        torch.cuda.manual_seed_all(seed_n)\n",
    "\n",
    "        print('Subject %d' % (i + 1))\n",
    "        exp = ExP(i + 1, DATA_DIR, dirs, EPOCHS, N_AUG, N_SEG, gpus,\n",
    "                  evaluate_mode=evaluate_mode,\n",
    "                  heads=heads,\n",
    "                  emb_size=emb_size,\n",
    "                  depth=depth,\n",
    "                  dataset_type=dataset_type,\n",
    "                  eeg1_f1=eeg1_f1,\n",
    "                  eeg1_kernel_size=eeg1_kernel_size,\n",
    "                  eeg1_D=eeg1_D,\n",
    "                  eeg1_pooling_size1=eeg1_pooling_size1,\n",
    "                  eeg1_pooling_size2=eeg1_pooling_size2,\n",
    "                  eeg1_dropout_rate=eeg1_dropout_rate,\n",
    "                  flatten_eeg1=flatten_eeg1,\n",
    "                  validate_ratio=validate_ratio)\n",
    "        testAcc, Y_true, Y_pred, df_process, best_epoch = exp.train()\n",
    "        true_cpu = Y_true.cpu().numpy().astype(int)\n",
    "        pred_cpu = Y_pred.cpu().numpy().astype(int)\n",
    "        df_pred_true = pd.DataFrame({'pred': pred_cpu, 'true': true_cpu})\n",
    "        df_pred_true.to_excel(pred_true_write, sheet_name=str(i + 1))\n",
    "        y_true_pred_dict[i] = df_pred_true\n",
    "\n",
    "        accuracy, precison, recall, f1, kappa = calMetrics(true_cpu, pred_cpu)\n",
    "        subject_result = {\n",
    "            'accuray': accuracy * 100,\n",
    "            'precision': precison * 100,\n",
    "            'recall': recall * 100,\n",
    "            'f1': f1 * 100,\n",
    "            'kappa': kappa * 100\n",
    "        }\n",
    "        subjects_result.append(subject_result)\n",
    "        df_process.to_excel(process_write, sheet_name=str(i + 1))\n",
    "        best_epochs.append(best_epoch)\n",
    "    \n",
    "        print(' THE BEST ACCURACY IS ' + str(testAcc) + \"\\tkappa is \" + str(kappa))\n",
    "        endtime = datetime.datetime.now()\n",
    "        print('subject %d duration: ' % (i + 1) + str(endtime - starttime))\n",
    "\n",
    "    df_result = pd.DataFrame(subjects_result)\n",
    "    process_write.close()\n",
    "    pred_true_write.close()\n",
    "\n",
    "    print('**The average Best accuracy is: ' + str(df_result['accuray'].mean()) + \n",
    "          \" kappa is: \" + str(df_result['kappa'].mean()) + \"\\n\")\n",
    "    print(\"best epochs: \", best_epochs)\n",
    "\n",
    "    mean = df_result.mean(axis=0)\n",
    "    mean.name = 'mean'\n",
    "    std = df_result.std(axis=0)\n",
    "    std.name = 'std'\n",
    "    df_result = pd.concat([df_result, pd.DataFrame(mean).T, pd.DataFrame(std).T])\n",
    "    df_result.to_excel(result_write_metric, index=False)\n",
    "\n",
    "    print('-' * 9, ' all result ', '-' * 9)\n",
    "    print(df_result)\n",
    "    print(\"*\" * 40)\n",
    "    result_write_metric.close()\n",
    "\n",
    "    return df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9400664e-210e-4d9b-8ed3-31f6e3e12979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 8, 22, 1000]           8,000\n",
      "       BatchNorm2d-2          [-1, 8, 22, 1000]              16\n",
      "               ELU-3          [-1, 8, 22, 1000]               0\n",
      "            Conv2d-4          [-1, 16, 1, 1000]             352\n",
      "       BatchNorm2d-5          [-1, 16, 1, 1000]              32\n",
      "               ELU-6          [-1, 16, 1, 1000]               0\n",
      "         AvgPool2d-7           [-1, 16, 1, 125]               0\n",
      "           Dropout-8           [-1, 16, 1, 125]               0\n",
      "            Conv2d-9           [-1, 16, 1, 125]           4,096\n",
      "      BatchNorm2d-10           [-1, 16, 1, 125]              32\n",
      "              ELU-11           [-1, 16, 1, 125]               0\n",
      "        AvgPool2d-12            [-1, 16, 1, 15]               0\n",
      "          Dropout-13            [-1, 16, 1, 15]               0\n",
      "           Conv2d-14            [-1, 16, 1, 15]             256\n",
      "        Rearrange-15               [-1, 15, 16]               0\n",
      "PatchEmbeddingCNN-16               [-1, 15, 16]               0\n",
      "          Dropout-17               [-1, 15, 16]               0\n",
      "PositionalEncoding-18               [-1, 15, 16]               0\n",
      "        LayerNorm-19               [-1, 15, 16]              32\n",
      "            Mamba-20               [-1, 15, 16]               0\n",
      "          Dropout-21               [-1, 15, 16]               0\n",
      "        LayerNorm-22               [-1, 15, 16]              32\n",
      "           Linear-23               [-1, 15, 64]           1,088\n",
      "             GELU-24               [-1, 15, 64]               0\n",
      "          Dropout-25               [-1, 15, 64]               0\n",
      "           Linear-26               [-1, 15, 16]           1,040\n",
      "          Dropout-27               [-1, 15, 16]               0\n",
      "MambaEncoderBlock-28               [-1, 15, 16]               0\n",
      "        LayerNorm-29               [-1, 15, 16]              32\n",
      "            Mamba-30               [-1, 15, 16]               0\n",
      "          Dropout-31               [-1, 15, 16]               0\n",
      "        LayerNorm-32               [-1, 15, 16]              32\n",
      "           Linear-33               [-1, 15, 64]           1,088\n",
      "             GELU-34               [-1, 15, 64]               0\n",
      "          Dropout-35               [-1, 15, 64]               0\n",
      "           Linear-36               [-1, 15, 16]           1,040\n",
      "          Dropout-37               [-1, 15, 16]               0\n",
      "MambaEncoderBlock-38               [-1, 15, 16]               0\n",
      "        LayerNorm-39               [-1, 15, 16]              32\n",
      "            Mamba-40               [-1, 15, 16]               0\n",
      "          Dropout-41               [-1, 15, 16]               0\n",
      "        LayerNorm-42               [-1, 15, 16]              32\n",
      "           Linear-43               [-1, 15, 64]           1,088\n",
      "             GELU-44               [-1, 15, 64]               0\n",
      "          Dropout-45               [-1, 15, 64]               0\n",
      "           Linear-46               [-1, 15, 16]           1,040\n",
      "          Dropout-47               [-1, 15, 16]               0\n",
      "MambaEncoderBlock-48               [-1, 15, 16]               0\n",
      "        LayerNorm-49               [-1, 15, 16]              32\n",
      "            Mamba-50               [-1, 15, 16]               0\n",
      "          Dropout-51               [-1, 15, 16]               0\n",
      "        LayerNorm-52               [-1, 15, 16]              32\n",
      "           Linear-53               [-1, 15, 64]           1,088\n",
      "             GELU-54               [-1, 15, 64]               0\n",
      "          Dropout-55               [-1, 15, 64]               0\n",
      "           Linear-56               [-1, 15, 16]           1,040\n",
      "          Dropout-57               [-1, 15, 16]               0\n",
      "MambaEncoderBlock-58               [-1, 15, 16]               0\n",
      "        LayerNorm-59               [-1, 15, 16]              32\n",
      "            Mamba-60               [-1, 15, 16]               0\n",
      "          Dropout-61               [-1, 15, 16]               0\n",
      "        LayerNorm-62               [-1, 15, 16]              32\n",
      "           Linear-63               [-1, 15, 64]           1,088\n",
      "             GELU-64               [-1, 15, 64]               0\n",
      "          Dropout-65               [-1, 15, 64]               0\n",
      "           Linear-66               [-1, 15, 16]           1,040\n",
      "          Dropout-67               [-1, 15, 16]               0\n",
      "MambaEncoderBlock-68               [-1, 15, 16]               0\n",
      "        LayerNorm-69               [-1, 15, 16]              32\n",
      "            Mamba-70               [-1, 15, 16]               0\n",
      "          Dropout-71               [-1, 15, 16]               0\n",
      "        LayerNorm-72               [-1, 15, 16]              32\n",
      "           Linear-73               [-1, 15, 64]           1,088\n",
      "             GELU-74               [-1, 15, 64]               0\n",
      "          Dropout-75               [-1, 15, 64]               0\n",
      "           Linear-76               [-1, 15, 16]           1,040\n",
      "          Dropout-77               [-1, 15, 16]               0\n",
      "MambaEncoderBlock-78               [-1, 15, 16]               0\n",
      "     MambaEncoder-79               [-1, 15, 16]               0\n",
      "          Flatten-80                  [-1, 240]               0\n",
      "          Dropout-81                  [-1, 240]               0\n",
      "           Linear-82                    [-1, 4]             964\n",
      "ClassificationHead-83                    [-1, 4]               0\n",
      "================================================================\n",
      "Total params: 26,900\n",
      "Trainable params: 26,900\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.08\n",
      "Forward/backward pass size (MB): 4.70\n",
      "Params size (MB): 0.10\n",
      "Estimated Total Size (MB): 4.88\n",
      "----------------------------------------------------------------\n",
      "Wed Apr 16 13:30:13 2025\n",
      "seed is 1917\n",
      "Subject 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "EEGMamba.__init__() got an unexpected keyword argument 'database_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 61\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(time\u001b[38;5;241m.\u001b[39masctime(time\u001b[38;5;241m.\u001b[39mlocaltime(time\u001b[38;5;241m.\u001b[39mtime())))\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# NOTE: The following call had a syntax issue in the original script.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Make sure to remove any stray tokens (e.g., \"ExP(i + 1\") when calling main.\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRESULT_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m              \u001b[49m\u001b[43mevaluate_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEVALUATE_MODE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m              \u001b[49m\u001b[43mheads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHEADS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m              \u001b[49m\u001b[43memb_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEMB_DIM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m              \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEPTH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m              \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m              \u001b[49m\u001b[43meeg1_f1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEEGNet1_F1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m              \u001b[49m\u001b[43meeg1_kernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEEGNet1_KERNEL_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m              \u001b[49m\u001b[43meeg1_D\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEEGNet1_D\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m              \u001b[49m\u001b[43meeg1_pooling_size1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEEGNet1_POOL_SIZE1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m              \u001b[49m\u001b[43meeg1_pooling_size2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEEGNet1_POOL_SIZE2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m              \u001b[49m\u001b[43meeg1_dropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEEGNet1_DROPOUT_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m              \u001b[49m\u001b[43mflatten_eeg1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLATTEN_EEGNet1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m              \u001b[49m\u001b[43mvalidate_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_ratio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(time\u001b[38;5;241m.\u001b[39masctime(time\u001b[38;5;241m.\u001b[39mlocaltime(time\u001b[38;5;241m.\u001b[39mtime())))\n",
      "Cell \u001b[0;32mIn[5], line 49\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(dirs, evaluate_mode, heads, emb_size, depth, dataset_type, eeg1_f1, eeg1_kernel_size, eeg1_D, eeg1_pooling_size1, eeg1_pooling_size2, eeg1_dropout_rate, flatten_eeg1, validate_ratio)\u001b[0m\n\u001b[1;32m     46\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed_all(seed_n)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubject \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 49\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[43mExP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_AUG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_SEG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m          \u001b[49m\u001b[43mevaluate_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluate_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m          \u001b[49m\u001b[43mheads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m          \u001b[49m\u001b[43memb_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memb_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m          \u001b[49m\u001b[43meeg1_f1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meeg1_f1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m          \u001b[49m\u001b[43meeg1_kernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meeg1_kernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m          \u001b[49m\u001b[43meeg1_D\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meeg1_D\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m          \u001b[49m\u001b[43meeg1_pooling_size1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meeg1_pooling_size1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m          \u001b[49m\u001b[43meeg1_pooling_size2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meeg1_pooling_size2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m          \u001b[49m\u001b[43meeg1_dropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meeg1_dropout_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m          \u001b[49m\u001b[43mflatten_eeg1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflatten_eeg1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidate_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_ratio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m testAcc, Y_true, Y_pred, df_process, best_epoch \u001b[38;5;241m=\u001b[39m exp\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     64\u001b[0m true_cpu \u001b[38;5;241m=\u001b[39m Y_true\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 58\u001b[0m, in \u001b[0;36mExP.__init__\u001b[0;34m(self, nsub, data_dir, result_name, epochs, number_aug, number_seg, gpus, evaluate_mode, heads, emb_size, depth, dataset_type, eeg1_f1, eeg1_kernel_size, eeg1_D, eeg1_pooling_size1, eeg1_pooling_size2, eeg1_dropout_rate, flatten_eeg1, validate_ratio, learning_rate, batch_size)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumber_class, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumber_channel \u001b[38;5;241m=\u001b[39m numberClassChannel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_type)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Instantiate the EEGMamba model.\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mEEGMamba\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43memb_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memb_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43meeg1_f1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meeg1_f1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43meeg1_kernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meeg1_kernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43meeg1_D\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meeg1_D\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43meeg1_pooling_size1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meeg1_pooling_size1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43meeg1_pooling_size2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meeg1_pooling_size2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43meeg1_dropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meeg1_dropout_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43meeg1_number_channel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumber_channel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflatten_eeg1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflatten_eeg1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/model_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnSub)\n",
      "\u001b[0;31mTypeError\u001b[0m: EEGMamba.__init__() got an unexpected keyword argument 'database_type'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cell 9: Main Execution Block\n",
    "----------------------------\n",
    "- Set hyperparameters such as the data directory, evaluation mode, number of subjects,\n",
    "  epochs, embedding dimensions, etc.\n",
    "- Iterates over parameter sets (e.g., different dataset types).\n",
    "- Constructs the EEGMamba model and prints a summary.\n",
    "- Calls the main function to run the full pipeline.\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage and hyperparameter settings.\n",
    "    DATA_DIR = r'bci2a/'\n",
    "    EVALUATE_MODE = 'LOSO-No'\n",
    "    N_SUBJECT = 9\n",
    "    N_AUG = 3\n",
    "    N_SEG = 8\n",
    "    EPOCHS = 1000\n",
    "    EMB_DIM = 16\n",
    "    HEADS = 2\n",
    "    DEPTH = 6\n",
    "    TYPE = 'B'\n",
    "    validate_ratio = 0.3\n",
    "\n",
    "    EEGNet1_F1 = 8\n",
    "    EEGNet1_KERNEL_SIZE = 1000\n",
    "    EEGNet1_D = 2\n",
    "    EEGNet1_POOL_SIZE1 = 8\n",
    "    EEGNet1_POOL_SIZE2 = 8\n",
    "    FLATTEN_EEGNet1 = 2000\n",
    "    if EVALUATE_MODE != 'LOSO':\n",
    "        EEGNet1_DROPOUT_RATE = 0.5\n",
    "    else:\n",
    "        EEGNet1_DROPOUT_RATE = 0.25    \n",
    "\n",
    "    parameters_list = ['A']\n",
    "    for TYPE in parameters_list:\n",
    "        number_class, number_channel = numberClassChannel(TYPE)\n",
    "        RESULT_NAME = \"CTNetMamba_{}_heads_{}_depth_{}_{}\".format(TYPE, HEADS, DEPTH, int(time.time()))\n",
    "\n",
    "        # Instantiate the model and print its summary.\n",
    "        sModel = EEGMamba(\n",
    "            emb_size=EMB_DIM,\n",
    "            depth=DEPTH,\n",
    "            n_classes=number_class,  # Provide the number of classes here.\n",
    "            eeg1_f1=EEGNet1_F1,\n",
    "            eeg1_kernel_size=EEGNet1_KERNEL_SIZE,\n",
    "            eeg1_pooling_size1=EEGNet1_POOL_SIZE1,\n",
    "            eeg1_pooling_size2=EEGNet1_POOL_SIZE2,\n",
    "            eeg1_dropout_rate=EEGNet1_DROPOUT_RATE,\n",
    "            eeg1_number_channel=number_channel\n",
    "            # Add any additional parameters as needed.\n",
    "        ).cuda()\n",
    "\n",
    "        summary(sModel, (1, number_channel, 1000))\n",
    "\n",
    "        print(time.asctime(time.localtime(time.time())))\n",
    "        \n",
    "        # NOTE: The following call had a syntax issue in the original script.\n",
    "        # Make sure to remove any stray tokens (e.g., \"ExP(i + 1\") when calling main.\n",
    "        result = main(RESULT_NAME,\n",
    "                      evaluate_mode=EVALUATE_MODE,\n",
    "                      heads=HEADS,\n",
    "                      emb_size=EMB_DIM,\n",
    "                      depth=DEPTH,\n",
    "                      dataset_type=TYPE,\n",
    "                      eeg1_f1=EEGNet1_F1,\n",
    "                      eeg1_kernel_size=EEGNet1_KERNEL_SIZE,\n",
    "                      eeg1_D=EEGNet1_D,\n",
    "                      eeg1_pooling_size1=EEGNet1_POOL_SIZE1,\n",
    "                      eeg1_pooling_size2=EEGNet1_POOL_SIZE2,\n",
    "                      eeg1_dropout_rate=EEGNet1_DROPOUT_RATE,\n",
    "                      flatten_eeg1=FLATTEN_EEGNet1,\n",
    "                      validate_ratio=validate_ratio)\n",
    "        print(time.asctime(time.localtime(time.time())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c85902-0fb6-4ad2-9289-ff725fc596da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mamba_working)",
   "language": "python",
   "name": "mamba_working"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
